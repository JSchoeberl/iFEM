{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "gross-insider",
   "metadata": {},
   "source": [
    "The Chebyshev Method\n",
    "===\n",
    "Let $A$ be SPD, and $C$ an SPD preconditioner. If we perform $n$ steps of the Richardson iteration with damping parameter $\\tau$, the error $e^n$ follows from the initial error $e^0$ via \n",
    "\n",
    "$$\n",
    "e^n = (I - \\tau C^{-1} A)^n e^0.\n",
    "$$\n",
    "\n",
    "Now, we allow to use different damping parameters $\\tau_k$ in every iteration. Then\n",
    "\n",
    "$$\n",
    "e^n = (I - \\tau_n C^{-1} A) \\cdots (I - \\tau_2 C^{-1} A )(I - \\tau_1 C^{-1} A) e^0.\n",
    "$$\n",
    "\n",
    "With the polynomial\n",
    "\n",
    "$$\n",
    "p(\\lambda) = \\Pi_{i=1}^n (1 - \\tau_i \\lambda)\n",
    "$$\n",
    "\n",
    "we can write \n",
    "\n",
    "$$\n",
    "e^n = p(C^{-1} A) e^0\n",
    "$$\n",
    "\n",
    "We observe that $p(.)$ is a polynomial of degree $n$, such that $p(0) = 1$. Let $(\\lambda_i, z^i)$ be the eigen-system of $C^{-1} A$, and expand errors with respect to the $C$-orthonormal eigen-basis:\n",
    "\n",
    "$$\n",
    "\\| e^n \\|_C^2 = \\sum_{i=1}^N (e^n_i)^2 = \\sum_{i=1}^N \\big( p(\\lambda_i) {e^0_i} \\big)^2 \\leq \\max_{\\lambda_i \\in \\sigma(C^{-1} A)} p(\\lambda_i)^2 \\; \\| e^0 \\|_C^2\n",
    "$$\n",
    "\n",
    "\n",
    "The goal is now to find damping parameters $\\tau_1, \\ldots \\tau_n$ such that\n",
    "\n",
    "$$\n",
    "\\max_{\\lambda_i \\in \\sigma(C^{-1} A)} | p(\\lambda_i) |\n",
    "$$\n",
    "\n",
    "is minimal. It is rarely feasible to work with the precise spectrum. But often we have bounds such that $\\sigma(C^{-1} A) \\subset [\\gamma_1, \\gamma_2]$ with $0 < \\gamma_1 < \\gamma_2$. Then, we can simplify the problem to optimize the polynomial such that\n",
    "\n",
    "$$\n",
    "\\min_{p \\in \\text{Pol(n)} \\atop p(0) = 1} \\max_{\\lambda \\in [\\gamma_1, \\gamma_2]}\n",
    " | p(\\lambda) |\n",
    "$$\n",
    "\n",
    "The solution to this min-max problem is given by Chebyshev polynomials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "straight-conducting",
   "metadata": {},
   "source": [
    "Chebyshev polynomials\n",
    "---\n",
    "\n",
    "Chebyshev polynomials (of the first kind) are defined via the three-term recurrence relation \n",
    "\n",
    "\\begin{eqnarray*}\n",
    "T_0(x) & = & 1 \\\\\n",
    "T_1(x) & = & x \\\\\n",
    "T_{n+1}(x) & = & 2 x T_n(x) - T_{n-1}(x) \\qquad n \\geq 1\n",
    "\\end{eqnarray*}\n",
    "\n",
    "Using induction and trigonometric addition formulas one easily \n",
    "shows that\n",
    "\n",
    "$$\n",
    "T_n(x) = \\cos( n \\arccos (x)) \\qquad \\text{for} \\; x \\in [-1,1]\n",
    "$$\n",
    "\n",
    "and thus \n",
    "\n",
    "$$\n",
    "\\sup_{x \\in [-1,1]} T_n(x) = 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-certification",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cheby(n,x):\n",
    "    T,Told = x, 1+0*x     # for vectorization\n",
    "    for i in range(n):\n",
    "        T,Told = 2*x*T-Told, T\n",
    "    return Told"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-diversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "fig.canvas.toolbar_visible = True\n",
    "fig.canvas.header_visible = False\n",
    "ax.set_ylim([-3, 3])\n",
    "ax.grid(True)\n",
    "\n",
    "x = np.linspace(-1.2, 1.2, 500)\n",
    "for k in [1, 2, 5, 20]:\n",
    "    ax.plot (x, Cheby(k,x), label='T'+str(k))\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-hunger",
   "metadata": {},
   "source": [
    "We rescale \n",
    "* the argument such that $\\lambda = \\gamma_1$ is mapped to $-1$ and $\\lambda = \\gamma_2$ is mapped to $+1$,\n",
    "* and scale the range such that $\\widetilde T_n(0) = 1$:\n",
    "\n",
    "$$\n",
    "\\widetilde T_n(\\lambda) = \\frac{1}{T_n \\left(\\tfrac{-\\gamma_1-\\gamma_2}{\\gamma_2-\\gamma_1}\\right)} \n",
    "T_n \\left(\\tfrac{2 \\lambda -\\gamma_1-\\gamma_2}{\\gamma_2-\\gamma_1}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-straight",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ScaledCheby(n,lam,gamma1, gamma2):\n",
    "    x = (-gamma2-gamma1)/(gamma2-gamma1)+2/(gamma2-gamma1)*lam\n",
    "    fac = 1/Cheby(n, (-gamma2-gamma1)/(gamma2-gamma1))\n",
    "    return fac*Cheby(n,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-study",
   "metadata": {},
   "source": [
    "We compare the scaled Chebyshev polynomial to the error reduction of $n$ steps Richardson iteration for the error component in the eigen-space corresponding to an eigen-value $\\lambda$:\n",
    "$$\n",
    "(1 - \\tau_{\\text{opt}} \\lambda)^n \\qquad \\text{with} \\qquad \\tau_\\text{opt} = \\frac{2}{\\gamma_1 + \\gamma_2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "periodic-railway",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "fig.canvas.toolbar_visible = True\n",
    "fig.canvas.header_visible = False\n",
    "\n",
    "ax.set_ylim([-1.5, 1.5])\n",
    "ax.grid(True)\n",
    "# ax.set_title(\"\")\n",
    " \n",
    "gamma2 = 1\n",
    "\n",
    "@widgets.interact(n=(0, 50, 1), gamma1=(0.01, 1, 0.01))\n",
    "def update(n = 5, gamma1=0.1):\n",
    "    s1 = np.linspace(0, gamma1, 500)\n",
    "    s2 = np.linspace(gamma1, gamma2, 500)\n",
    "    for l in list(ax.lines): l.remove()\n",
    "    ax.plot(s1, ScaledCheby(n,s1,gamma1, gamma2), color='r', linestyle='dashed')\n",
    "    ax.plot(s2, ScaledCheby(n,s2,gamma1, gamma2), color='r', label='Cheby')\n",
    "    tauopt = 2/(gamma1+gamma2)\n",
    "    ax.plot(s1, (1-tauopt*s1)**n, color='b', linestyle='dashed')\n",
    "    ax.plot(s2, (1-tauopt*s2)**n, color='b', label='Richardson')\n",
    "    \n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earned-intellectual",
   "metadata": {},
   "source": [
    "The maximum of $\\widetilde T$ on the interval $[\\gamma_1, \\gamma_2]$ is\n",
    "$$\n",
    "\\rho_n := \\frac{1}{T_n \\big(\\tfrac{-\\gamma_1-\\gamma_2}{\\gamma_2-\\gamma_1}\\big)}\n",
    "$$\n",
    "\n",
    "A representation of Chebyshev polynomials for $x \\not\\in [-1,1]$ is\n",
    "\n",
    "$$\n",
    "T_n(x) = \\frac{1}{2} \\, \\left[ \\big(x+\\sqrt{x^2-1}\\big)^n + \\big(x+\\sqrt{x^2-1}\\big)^{-n} \\right]\n",
    "$$\n",
    "\n",
    "which is also easily proven by induction. From this we get\n",
    "\n",
    "$$\n",
    "\\rho_n = \\frac{2 c^n}{1 + c^{2n}} \\qquad \\text{with} \\qquad \n",
    "c = \\frac{\\sqrt{\\gamma_2} - \\sqrt{\\gamma_1}}\n",
    "{ \\sqrt{\\gamma_2}+\\sqrt{\\gamma_1}}\n",
    "$$\n",
    "\n",
    "With the condition number $\\kappa = \\gamma_2 / \\gamma_2$ there is\n",
    "\n",
    "$$\n",
    "c \\approx 1 - \\frac{2}{\\sqrt{\\kappa}} \\qquad \\text{and} \\qquad\n",
    "\\rho_n \\approx \\big( 1 - \\tfrac{2}{\\sqrt{\\kappa}} \\big) ^n\n",
    "$$\n",
    "\n",
    "To achieve an error reduction by $\\rho_n = \\varepsilon$ one needs\n",
    "\n",
    "$$\n",
    "n \\approx \\log \\varepsilon^{-1} \\sqrt{\\kappa}\n",
    "$$\n",
    "\n",
    "iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-monday",
   "metadata": {},
   "source": [
    "The Chebyshev iteration\n",
    "---\n",
    "\n",
    "If we choose the optimal damping parameters $\\tau_i$ for $n$ steps we obtain an error \n",
    "\n",
    "$$\n",
    "e^n = \\widetilde T_n(C^{-1} A) e^0\n",
    "$$\n",
    "\n",
    "or substituting back\n",
    "\n",
    "$$\n",
    "e^n = \\frac{1}{T_n\\big(\\tfrac{-\\gamma_2-\\gamma_1}{\\gamma_2-\\gamma_1}\\big)} T_n\\big( \\tfrac{-\\gamma_2-\\gamma_1}{\\gamma_2-\\gamma_1} I\n",
    "+ \\tfrac{2}{\\gamma_2-\\gamma_1} C^{-1} A \\big) e^0\n",
    "$$\n",
    "\n",
    "defining $t_n = T_{n} \\big( \\tfrac{-\\gamma_2-\\gamma_1}{\\gamma_2-\\gamma_1} \\big)$ and shifting the index we have\n",
    "\n",
    "$$\n",
    "t_{n+1} e^{n+1} = T_{n+1} \\big( \\tfrac{-\\gamma_2-\\gamma_1}{\\gamma_2-\\gamma_1} I\n",
    "+ \\tfrac{2}{\\gamma_2-\\gamma_1} C^{-1} A \\big) e^0\n",
    "$$\n",
    "\n",
    "using the three-term recurrence we obtain\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "t_{n+1} e^{n+1} \n",
    "& = & 2 \\big( \\tfrac{-\\gamma_2-\\gamma_1}{\\gamma_2-\\gamma_1} I\n",
    "+ \\tfrac{2}{\\gamma_2-\\gamma_1} C^{-1} A \\big) T_n \\big( \\ldots \\big) e^0 - T_{n-1} \\big( \\ldots \\big) e^0 \\\\\n",
    "& = & 2 \\big( \\tfrac{-\\gamma_2-\\gamma_1}{\\gamma_2-\\gamma_1} I\n",
    "+ \\tfrac{2}{\\gamma_2-\\gamma_1} C^{-1} A \\big) t_n e^n  - t_{n-1} e^{n-1}\n",
    "\\end{eqnarray*}\n",
    "\n",
    "inserting also the recurrence for the $t_n$ we have\n",
    "\n",
    "$$\n",
    "\\big( 2 \\tfrac{-\\gamma_2-\\gamma_1}{\\gamma_2-\\gamma_1} t_n - t_{n-1} \\big) e^{n+1} \n",
    "= 2 \\big( \\tfrac{-\\gamma_2-\\gamma_1}{\\gamma_2-\\gamma_1} I\n",
    "+ \\tfrac{2}{\\gamma_2-\\gamma_1} C^{-1} A \\big) t_n e^n  - t_{n-1} e^{n-1}\n",
    "$$\n",
    "\n",
    "Now, we use that the error is $e^n = x^n - x^\\ast$:\n",
    "\n",
    "$$\n",
    "\\big( 2 \\tfrac{-\\gamma_2-\\gamma_1}{\\gamma_2-\\gamma_1} t_n - t_{n-1} \\big) (x^{n+1} - x^\\ast)\n",
    "= 2 \\big( \\tfrac{-\\gamma_2-\\gamma_1}{\\gamma_2-\\gamma_1} I\n",
    "+ \\tfrac{2}{\\gamma_2-\\gamma_1} C^{-1} A \\big) t_n (x^n-x^\\ast)  - t_{n-1} (x^{n-1} - x^\\ast)\n",
    "$$\n",
    "\n",
    "Most $x^\\ast$ cancel out, and thus\n",
    "\n",
    "$$\n",
    "t_{n+1} x^{n+1} = 2 \\tfrac{-\\gamma_2-\\gamma_1}{\\gamma_2-\\gamma_1} t_n x^n - t_{n-1} x^{n-1} + \\tfrac{4 t_n}{\\gamma_2 - \\gamma_1} C^{-1} (A x^n - \n",
    "\\underbrace{A x^\\ast}_b)\n",
    "$$\n",
    "\n",
    "This is an algorithm to compute the iterates $x^n$. The new iterate follows from the previous two, and from the (preconditioned) residual $C^{-1} (b - A x^n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-worcester",
   "metadata": {},
   "source": [
    "Instead of working with three iterates $x^k$, we can introduce the increment\n",
    "\n",
    "$$\n",
    "d^n = x^{n+1}-x^n\n",
    "$$\n",
    "\n",
    "Using $x^{n+1} = x^n + d^n$ and $x^{n-1} = x^n - d^{n-1}$ we obtain\n",
    "\n",
    "$$\n",
    "t_{n+1} (x^{n}+d^n) = 2 \\tfrac{-\\gamma_2-\\gamma_1}{\\gamma_2-\\gamma_1} t_n x^n - t_{n-1} (x^{n}-d^{n-1}) + \\tfrac{4 t_n}{\\gamma_2 - \\gamma_1} C^{-1} (A x^n - b).\n",
    "$$\n",
    "\n",
    "By the three-term recurrence for $t_n$ there is $t_{n+1} = 2 \\tfrac{-\\gamma_2-\\gamma_1}{\\gamma_2-\\gamma_1} t_n - t_{n-1}$.  Thus, $x^n$ cancel out and we have an update formula for $d$:\n",
    "\n",
    "$$\n",
    "t_{n+1} d^n = t_{n-1} d^{n-1} + \\tfrac{4 t_n}{\\gamma_2 - \\gamma_1} C^{-1} (A x^n - b)\n",
    "$$\n",
    "\n",
    "Finally, we define $\\rho_n = \\frac{t_n}{t_{n+1}}$ which satisfies the recurrence \n",
    "$\\rho_n = \\big( 2 \\tfrac{-\\gamma_1-\\gamma_2}{\\gamma2-\\gamma1} - \\rho_{n-1}\\big)^{-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-industry",
   "metadata": {},
   "source": [
    "The final algorithm is taken from Yousef Saad: \"Iterative Methods for Sparse Linear Systems\" <br>\n",
    "Algorithm 12.1 on page 399:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-client",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ChebyIteration(A, b, pre, gamma1, gamma2, tol=1e-8, maxit=200):\n",
    "    x = b.CreateVector()\n",
    "    r = b.CreateVector()\n",
    "    w = b.CreateVector()\n",
    "    d = b.CreateVector()\n",
    "   \n",
    "    x[:] = 0\n",
    "    r.data = b - A*x\n",
    "    \n",
    "    theta = (gamma1+gamma2)/2\n",
    "    delta = (gamma2-gamma1)/2\n",
    "    sigma1 = theta/delta\n",
    "    rho = 1/sigma1\n",
    "    w.data = pre*r\n",
    "    d.data = 1/theta * w\n",
    "    \n",
    "    err0 = sqrt(InnerProduct(r,w))\n",
    "    for it in range(maxit):\n",
    "        x += d\n",
    "        r -= A * d\n",
    "        w.data = pre * r\n",
    "        err = sqrt(InnerProduct(w,r))\n",
    "        print (\"Iteration\", it, \"err=\", err)\n",
    "        d.data *= rho\n",
    "        d.data += 2/delta * pre * r\n",
    "        rho = 1/(2*sigma1-rho)\n",
    "        d.data *= rho\n",
    "        if err < tol*err0: break\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-password",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ngsolve import *\n",
    "from netgen.geom2d import unit_square\n",
    "mesh = Mesh(unit_square.GenerateMesh(maxh=0.1))\n",
    "fes = H1(mesh, order=1)\n",
    "u,v = fes.TnT()\n",
    "a = BilinearForm(grad(u)*grad(v)*dx+10*u*v*dx).Assemble()\n",
    "f = LinearForm(x*y*v*dx).Assemble()\n",
    "gfu = GridFunction(fes)\n",
    "pre = a.mat.CreateSmoother()   # Jacobi preconditioner\n",
    "# pre = IdentityMatrix(a.mat.height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-diversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ngsolve.la import EigenValues_Preconditioner\n",
    "lams = list(EigenValues_Preconditioner(mat=a.mat, pre=pre))\n",
    "gamma1, gamma2 = lams[0], lams[-1]\n",
    "print (gamma1,gamma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-victorian",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gfu.vec.data = ChebyIteration(a.mat, f.vec, pre, gamma1, gamma2, maxit=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "false-pharmacy",
   "metadata": {},
   "source": [
    "Experiments: \n",
    "* modify the mesh-size\n",
    "* how sensitive is the method when under/over-estimating $\\gamma_1$ ?\n",
    "* and $\\gamma_2$ ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-swing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ngsolve.webgui import Draw\n",
    "Draw (gfu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-armstrong",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
