{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "demographic-baker",
   "metadata": {},
   "source": [
    "The Richardson Iteration\n",
    "---\n",
    "also called simple iteration is the fixed point iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-dining",
   "metadata": {},
   "source": [
    "$$\n",
    "x^{k+1} := x^k + \\alpha \\, (b - A x^k)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-commander",
   "metadata": {},
   "source": [
    "with an arbitrary starting value $x^0 \\in R^n$, and a properly cosen damping paramter $\\alpha$.\n",
    "\n",
    "The solution $x^\\ast$ is a fixed point of the iteration (since $b - A x^\\ast = 0$).\n",
    "\n",
    "If we define the error as\n",
    "$$\n",
    "e^k = x^k - x^\\ast,\n",
    "$$\n",
    "\n",
    "the error propagation from one step to the next is\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "e^{k+1} & = & x^{k+1} - x^\\ast = x^k + \\alpha (b - A x^k) - x^\\ast \\\\\n",
    "& = & x^k - x^\\ast + \\alpha A (x^\\ast - x^k) = (I - \\alpha A) (x^k - x^\\ast)\n",
    "\\end{eqnarray*}\n",
    "\n",
    "This means the new error is obtained from the old error by the error propagation matrix\n",
    "\n",
    "$$\n",
    "e^{k+1} = (I - \\alpha A) \\, e^k\n",
    "$$\n",
    "\n",
    "Two strategies to verify convergence are:\n",
    "\n",
    "* prove that the convergence radius \n",
    "\n",
    "$$\n",
    "\\rho(I - \\alpha A) := \\max_{\\lambda \\in \\sigma(I - \\alpha A)} |\\lambda| < 1\n",
    "$$\n",
    "\n",
    "* find some norm $\\| \\cdot \\|$ such that the matrix norm (=operator norm)\n",
    "\n",
    "$$\n",
    "\\| I - \\alpha A \\| := \\sup_{x \\in R^n} \\frac{ \\| (I - \\alpha A) x \\| }{ \\| x \\| } < 1\n",
    "$$\n",
    "\n",
    "The first one, $\\rho < 1$, only provides asymptotic convergence. This is easily proven if A is diagonizable, i.e. it features a full set of eigenvectors $z^j$ and eigenvalues $\\lambda_j$. Expand the initial error as\n",
    "$$\n",
    "e^0 = \\sum_j e^0_j z^j,\n",
    "$$\n",
    "then\n",
    "$$\n",
    "e^k = \\sum_j (1-\\alpha \\lambda_j)^k e^0_j z^j\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\| e^k \\| \\leq \\rho^k  \\sum_j | e^0_j | \\| z^j \\|\n",
    "$$\n",
    "This means $\\| e^k \\| \\leq C \\rho^k$, the the error does not have to decrease monotonically.\n",
    "\n",
    "However, if $\\| I - \\alpha A \\| < 1$, then\n",
    "$$\n",
    "\\| e^k \\| \\leq \\| I - \\alpha A \\| \\, \\| e^k \\|,\n",
    "$$\n",
    "and the error decreases in every interation step. Note that the matrix norm is the operator norm generated by the vector norm.\n",
    "\n",
    "Some facts:\n",
    "* If the norm $\\| \\cdot \\|$ is generated by an inner product $\\left< \\cdot, \\cdot \\right>$ (parallelogram identity), and $M$ is some self adjoint matrix with respect to this inner product, i.e.\n",
    "$$\n",
    "\\left< M x, y \\right>  = \\left< x, M y \\right>,\n",
    "$$\n",
    "  then $\\rho(M) = \\| M \\|$\n",
    "\n",
    "  If $\\left< \\cdot , \\cdot \\right>$ is the Euklidean inner product, then $M$ is self-adjoint exactly when $M$ is symmetric.\n",
    "  \n",
    "* Every operator operator norm is bounded by the spectral radius. There exists some norm such that the operator norm is arbitrary close to the spectral radius, i.e.\n",
    "$$\n",
    "\\rho(M) = \\sup_{ \\text{norms} \\| \\cdot \\| } \\| M \\|\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patient-recording",
   "metadata": {},
   "source": [
    "Optimizing the relaxation parameter $\\alpha$\n",
    "---\n",
    "Let $A$ be SPD, and let $\\sigma(A) = \\{ \\lambda_i \\in R \\}$ with $0 < \\lambda_1 \\leq \\lambda_2 \\ldots \\leq \\lambda_n$.\n",
    "\n",
    "Then the eigenvalues of $M = I - \\alpha A$ are $\\{ 1 - \\alpha \\lambda_i  \\}$. \n",
    "\n",
    "Whenever we choose \n",
    "$$\n",
    "0 < \\alpha < \\frac{2}{\\lambda_n}\n",
    "$$\n",
    "we obtain $\\rho(M) < 1$ and a convergent iteration.\n",
    "\n",
    "\n",
    "The spectral radius of $M$ is \n",
    "\n",
    "$$\n",
    "\\rho(M) = \\max \\{ | 1 - \\alpha \\lambda_i| \\}  = \n",
    "\\max \\{ 1 - \\alpha \\lambda_1, - (1-\\alpha \\lambda_n) \\}\n",
    "$$\n",
    "\n",
    "The maximum is minimized if we choose $\\alpha$ optimally such that\n",
    "$$\n",
    "1 - \\alpha \\lambda_1 = - (1 - \\alpha \\lambda_n),\n",
    "$$\n",
    "i.e.\n",
    "$$\n",
    "\\alpha_{\\text{opt}} = \\frac{2}{\\lambda_1 + \\lambda_n} \n",
    "$$\n",
    "leading to the optimal convergence rate\n",
    "\n",
    "$$\n",
    "\\rho_{\\text{opt}} = \\frac{\\lambda_n - \\lambda_1}{\\lambda_n+\\lambda_1}\n",
    "\\approx 1 - 2 \\frac{\\lambda_1}{\\lambda_n} = 1 - \\frac{2}{\\kappa(A)}\n",
    "$$\n",
    "\n",
    "with the condition number $\\kappa(A) = \\lambda_n(A) / \\lambda_1(A)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-mount",
   "metadata": {},
   "source": [
    "Experiments with the Richardson iteration\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-lancaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ngsolve import *\n",
    "from netgen.geom2d import unit_square\n",
    "mesh = Mesh(unit_square.GenerateMesh(maxh=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-violin",
   "metadata": {},
   "outputs": [],
   "source": [
    "fes = H1(mesh, order=1)\n",
    "u,v = fes.TnT()\n",
    "a = BilinearForm(grad(u)*grad(v)*dx+10*u*v*dx).Assemble()\n",
    "f = LinearForm(x*y*v*dx).Assemble()\n",
    "gfu = GridFunction(fes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-paraguay",
   "metadata": {},
   "source": [
    "we determine (an approximation to) the largest eigenvalue by a few steps of the power iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-wallace",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv = gfu.vec.CreateVector()\n",
    "hv2 = gfu.vec.CreateVector()\n",
    "hv.SetRandom()\n",
    "hv.data /= Norm(hv)\n",
    "for k in range(20):\n",
    "    hv2.data = a.mat * hv\n",
    "    rho = Norm(hv2)\n",
    "    print (rho)\n",
    "    hv.data = 1/rho * hv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-wells",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1 / rho\n",
    "r = f.vec.CreateVector()\n",
    "gfu.vec[:] = 0\n",
    "err0 = Norm(f.vec)\n",
    "its = 0\n",
    "while True:\n",
    "    r.data = f.vec - a.mat * gfu.vec\n",
    "    err = Norm(r)\n",
    "    print (\"iteration\", its, \"res=\", err)\n",
    "    gfu.vec.data += alpha * r\n",
    "    if err < 1e-8 * err0 or its > 10000: break\n",
    "    its = its+1\n",
    "print (\"needed\", its, \"iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-struggle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ngsolve.webgui import Draw\n",
    "Draw (gfu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-custody",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
